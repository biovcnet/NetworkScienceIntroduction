---
title: "Network Science Lesson 01"
output: html_notebook
---

In this lesson we will be generating a basic statistical association network form the Tara Oceans data that we can load into cytoscape.

# Installation

We'll need a few packages for this tutorial. Lets load them in. If you don't have any of these, you can install them using the `install.packages` function.

eg `install.packages("tidyverse")`

If you don't have SpiecEasi, you can dowload it as follows. Note, you need to `install.packages("devtools")` if you haven't ever done that before.

I commented the following lines out because I don't want to re-run them every time I test this notebook out. Uncomment them and run if you need them.

```{r}
#library(devtools)
#install_github("zdk123/SpiecEasi")
```

This took a while on my computer, you may want to get a cup of coffee while this runs.

# Loading Libraries

```{r}
library(tidyverse)
library(readxl)
library(SpiecEasi)
library(otuSummary)
pass <- function(x){x}
```

# Gathering data

First, lets dowload the Tara Oceans data from the internets.
This data are read numbers of different phyla level bacterial and archaeal groups.
They are 16s genes but are from shotgun metagenomic sequencing.

```{r}
TaraPhyla <- read_tsv("https://www.ebi.ac.uk/metagenomics/api/v1/studies/MGYS00000410/pipelines/2.0/file/ERP001736_phylum_taxonomy_abundances_v2.0.tsv")
```

Please look over the new TaraPhyla object in your global environment. You can see that the first two columns are the Kindom and Phylum information for a bunch of bacterial and archaeal phyla. The rest of the columns are the number of reads associated with those phyla at each station. The station names are at the top.

# Pre-processing

While I'm a tidy-verse fanatic and like working with data in dataframes. If you want to correlate everything vs everything, its often best to transmute our data into a data frame. 

```{r}
TaraPhylaMtx <- TaraPhyla %>%
  select(-kingdom)  %>% # remove kingdom column
  filter(phylum != "unassigned") %>%
  mutate(phylum = make.unique(phylum)) %>% # if you don't remove "unassigned, there are two phyla with this name and you have problems without this line
  column_to_rownames(var = "phylum") %>% # turn phylum into row.names of data frame
  as.matrix() %>% # transmogrify data.frame into matrix
  t() %>% # transpose, so the OTUs are the columns and samples are the rows
  pass
  
TaraPhylaMtx[1:5, 1:5] # Take a look at part of the matrix
```

# Simple correlation analysis
The simplist way to look for associations in data is through correlation analyis. There are some problems with applying correlations to this kind of data and we'll come back to that. For now though, lets calculate the spearman correlations on the data

```{r}
spearCor <- cor(TaraPhylaMtx, method = "spearman")
```

## Plotting the results

Here is a solution from here:
http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
```{r}
## Helper functions
# Get lower triangle of the correlation matrix
  get_lower_tri<-function(cormat){
    cormat[upper.tri(cormat)] <- NA
    return(cormat)
  }
  # Get upper triangle of the correlation matrix
  get_upper_tri <- function(cormat){
    cormat[lower.tri(cormat)]<- NA
    return(cormat)
  }

reorder_cormat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
}

spearCor_reorder <- reorder_cormat(spearCor) %>% get_upper_tri()

spearCor_melt = reshape2::melt(spearCor_reorder) %>% na.omit()
```




```{r, fig.width= 10, fig.height = 10}
spearCor_melt %>% ggplot(aes(x = Var2, y = Var1, fill = value)) + geom_tile() + scale_fill_gradient2() + theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# As above, but using Clr to adjust for compositionality
STUB

# Analysisis with sparcc

At this point, I found this torial helpful.
https://rachaellappan.github.io/16S-analysis/correlation-between-otus-with-sparcc.html

`sparcc` expects a `matrix` with OTU columns and sample rows. We want to name the rows and columns with row and column names. Lets do this processing






It is recommended to remove any rows with fewer than two reads on average.
I haven't shown you how to do that.

```{r}
RowsToKeep <- apply(TaraPhylaMtx, 2, mean) > 2
TaraPhylaMtx <- TaraPhylaMtx[RowsToKeep,]
```


```{r}
out <- sparcc(TaraPhylaMtx)
```

Out is the output of sparcc. It contains a correlation and covariance matrix. Lets look at the first part of the correlation matrix.

```{r}
out$Cor[1:5, 1:5]
```

I'm kind of annoyed that it threw away my site names. Lets add them back

```{r}
rownames(out$Cor) <- colnames(TaraPhylaMtx)
colnames(out$Cor) <- colnames(TaraPhylaMtx)
rownames(out$Cov) <- colnames(TaraPhylaMtx)
colnames(out$Cov) <- colnames(TaraPhylaMtx)
#cout <- as.data.frame(out$Cor)
out$Cor[1:5, 1:5]
```

Better.

Next, we need to calculate p-values. We do that by bootstrapping the sparcc values and then calculating p-values from those. 

The text below bootstraps things.

```{r}
tp0 <- proc.time()
out2 <- sparccboot(TaraPhylaMtx, R = 100)
tp1 <- proc.time()
tp1 - tp0
```

This took four minutes on my laptop. So in principal, running 1000 permutations (recommended) would take about an 40 minutes or I could use the multicore option. Lets proceed with this 100 permutation version for now.

Here's a multicore version, if you have multiple cores on your computer you can use it and things will go faster.
Doesn't work in RStudio Cloud.

```{r}
# tp0 <- proc.time()
# out2 <- sparccboot(TaraPhylaMtx, R = 1000, ncpus = 7)
# tp1 <- proc.time()
# tp1 - tp0
```
elapsed 108 with 4 cores
77 with 8 cores

Then we calculate the p values form the bootstrapped values.

```{r}
outP <- pval.sparccboot(out2)
data.frame(outP$cors, outP$pvals) %>% head
```

You'll notice these values are hard to use because they don't tell you which p-values correspond to which species. I dug around online and found that these are the lower part of a diagnonal matrix. 
https://github.com/zdk123/SpiecEasi/issues/17
You can rescue the data as follows.

```{r}
cors <- outP$cors
pvals <- outP$pvals
sparCCpcors <- diag(0.5, nrow = dim(out$Cor)[1], ncol = dim(out$Cor)[1])
sparCCpcors[upper.tri(sparCCpcors, diag=FALSE)] <- cors
sparCCpcors <- sparCCpcors + t(sparCCpcors)

sparCCpval <- diag(0.5, nrow = dim(out$Cor)[1], ncol = dim(out$Cor)[1])
sparCCpval[upper.tri(sparCCpval, diag=FALSE)] <- pvals
sparCCpval <- sparCCpval + t(sparCCpval)

rownames(sparCCpcors) <- colnames(TaraPhylaMtx)
colnames(sparCCpcors) <- colnames(TaraPhylaMtx)
rownames(sparCCpval) <- colnames(TaraPhylaMtx)
colnames(sparCCpval) <- colnames(TaraPhylaMtx)

sparCCpcors[1:5, 1:5]
sparCCpval[1:5, 1:5]
```

For reasons that are unclear to me, the correlation values saved by the sparcc pval program are a little different than the ones from sparcc. We'll use these ones, for no particular reason. I've submitted an issue report here, which you can follow, in case anything happens:
https://github.com/zdk123/SpiecEasi/issues/121


Cytoscape expects the correlation matrix to be in "long" format. So each row is a pair of variables and their correlation.
Matrixconvert makes things long format and also only takes the lower diagonal of the matrix so we don't have duplicate values.

```{r}
sparCCpcorsLong <- matrixConvert(sparCCpcors) %>%  rename(phy1 = sp1, phy2 = sp2, sparCC = dist)
sparCCpvalLong <- matrixConvert(sparCCpval) %>%  rename(phy1 = sp1, phy2 = sp2, p = dist)
```

Now lets combine the data and save them out so we can load things into cytoscape.
```{r}
toWrite <- left_join(sparCCpcorsLong, sparCCpvalLong, by = c("phy1", "phy2")) 
toWrite %>% head
write_csv(toWrite, "TaraOceansSparCC_p100.csv")
```

